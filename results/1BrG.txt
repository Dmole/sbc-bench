sbc-bench v0.6.3 Hardkernel ODROID-N2 (Tue, 19 Feb 2019 00:17:34 +0000)

Distributor ID:	Ubuntu
Description:	Ubuntu 18.04.2 LTS
Release:	18.04
Codename:	bionic
Architecture:	arm64

/usr/bin/gcc (Ubuntu/Linaro 7.3.0-27ubuntu1~18.04) 7.3.0

Uptime: 00:17:34 up 2 min,  1 user,  load average: 1.00, 0.42, 0.16

Linux 4.9.156-14 (odroid) 	02/19/19 	_aarch64_	(6 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.64    0.00    1.31    0.17    0.00   97.87

Device             tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
mmcblk0          21.75       813.54        75.55     118671      11020
mmcblk0rpmb       0.03         0.11         0.00         16          0
mmcblk0boot1      0.74         2.96         0.00        432          0
mmcblk0boot0      0.74         2.96         0.00        432          0

              total        used        free      shared  buff/cache   available
Mem:           3.6G        146M        3.3G        3.4M        139M        3.4G
Swap:            0B          0B          0B



##########################################################################

Trying to check cpufreq OPP for A53 cluster (cpu0-cpu1):

Cpufreq OPP: 1992    Measured: 1985.517/1987.644/1985.590
Cpufreq OPP: 1896    Measured: 1889.412/1889.412/1889.147
Cpufreq OPP: 1704    Measured: 1693.799/1700.115/1698.219
Cpufreq OPP: 1608    Measured: 1602.211/1600.999/1597.474
Cpufreq OPP: 1512    Measured: 1505.838/1508.001/1505.732
Cpufreq OPP: 1398    Measured: 1391.892/1392.327/1391.637
Cpufreq OPP: 1200    Measured: 1194.268/1191.871/1193.551
Cpufreq OPP: 1000    Measured: 994.027/995.368/994.541
Cpufreq OPP:  667    Measured: 659.343/659.319/659.565
Cpufreq OPP:  500    Measured: 492.584/491.395/492.980
Cpufreq OPP:  250    Measured: 243.952/243.686/242.913
Cpufreq OPP:  100    Measured: 93.048/93.375/92.902

Trying to check cpufreq OPP for A73 cluster (cpu2-cpu5):

Cpufreq OPP: 1992    Measured: 1990.389/1990.291/1989.628
Cpufreq OPP: 1908    Measured: 1906.102/1905.652/1905.674
Cpufreq OPP: 1800    Measured: 1797.586/1797.786/1798.086
Cpufreq OPP: 1704    Measured: 1702.536/1701.710/1701.997
Cpufreq OPP: 1608    Measured: 1605.518/1605.957/1605.738
Cpufreq OPP: 1512    Measured: 1509.676/1509.905/1510.064
Cpufreq OPP: 1398    Measured: 1395.985/1396.543/1395.653
Cpufreq OPP: 1200    Measured: 1197.744/1197.785/1198.230
Cpufreq OPP: 1000    Measured: 998.145/997.964/998.458
Cpufreq OPP:  667    Measured: 664.082/664.069/664.476
Cpufreq OPP:  500    Measured: 498.281/497.203/497.823
Cpufreq OPP:  250    Measured: 247.613/247.653/247.650
Cpufreq OPP:  100    Measured: 97.571/97.496/97.991

##########################################################################

Executing tinymembench on a little core:

tinymembench v0.4.9 (simple benchmark for memory throughput and latency)

==========================================================================
== Memory bandwidth tests                                               ==
==                                                                      ==
== Note 1: 1MB = 1000000 bytes                                          ==
== Note 2: Results for 'copy' tests show how many bytes can be          ==
==         copied per second (adding together read and writen           ==
==         bytes would have provided twice higher numbers)              ==
== Note 3: 2-pass copy means that we are using a small temporary buffer ==
==         to first fetch data into it, and only then write it to the   ==
==         destination (source -> L1 cache, L1 cache -> destination)    ==
== Note 4: If sample standard deviation exceeds 0.1%, it is shown in    ==
==         brackets                                                     ==
==========================================================================

 C copy backwards                                     :   1825.0 MB/s (1.2%)
 C copy backwards (32 byte blocks)                    :   1919.9 MB/s (0.7%)
 C copy backwards (64 byte blocks)                    :   1903.3 MB/s (0.3%)
 C copy                                               :   1959.7 MB/s
 C copy prefetched (32 bytes step)                    :   1417.1 MB/s (0.2%)
 C copy prefetched (64 bytes step)                    :   1578.1 MB/s
 C 2-pass copy                                        :   1442.0 MB/s (0.2%)
 C 2-pass copy prefetched (32 bytes step)             :    940.1 MB/s
 C 2-pass copy prefetched (64 bytes step)             :    922.0 MB/s
 C fill                                               :   7207.4 MB/s
 C fill (shuffle within 16 byte blocks)               :   7208.2 MB/s
 C fill (shuffle within 32 byte blocks)               :   7206.9 MB/s
 C fill (shuffle within 64 byte blocks)               :   7205.0 MB/s
 ---
 standard memcpy                                      :   1966.4 MB/s
 standard memset                                      :   7203.3 MB/s
 ---
 NEON LDP/STP copy                                    :   1939.7 MB/s (0.3%)
 NEON LDP/STP copy pldl2strm (32 bytes step)          :   1251.3 MB/s (0.4%)
 NEON LDP/STP copy pldl2strm (64 bytes step)          :   1638.3 MB/s (0.2%)
 NEON LDP/STP copy pldl1keep (32 bytes step)          :   2161.3 MB/s
 NEON LDP/STP copy pldl1keep (64 bytes step)          :   2160.4 MB/s
 NEON LD1/ST1 copy                                    :   1936.7 MB/s (0.4%)
 NEON STP fill                                        :   7207.2 MB/s
 NEON STNP fill                                       :   3990.3 MB/s (0.4%)
 ARM LDP/STP copy                                     :   1942.1 MB/s (0.2%)
 ARM STP fill                                         :   7207.4 MB/s
 ARM STNP fill                                        :   3978.3 MB/s (0.3%)

==========================================================================
== Framebuffer read tests.                                              ==
==                                                                      ==
== Many ARM devices use a part of the system memory as the framebuffer, ==
== typically mapped as uncached but with write-combining enabled.       ==
== Writes to such framebuffers are quite fast, but reads are much       ==
== slower and very sensitive to the alignment and the selection of      ==
== CPU instructions which are used for accessing memory.                ==
==                                                                      ==
== Many x86 systems allocate the framebuffer in the GPU memory,         ==
== accessible for the CPU via a relatively slow PCI-E bus. Moreover,    ==
== PCI-E is asymmetric and handles reads a lot worse than writes.       ==
==                                                                      ==
== If uncached framebuffer reads are reasonably fast (at least 100 MB/s ==
== or preferably >300 MB/s), then using the shadow framebuffer layer    ==
== is not necessary in Xorg DDX drivers, resulting in a nice overall    ==
== performance improvement. For example, the xf86-video-fbturbo DDX     ==
== uses this trick.                                                     ==
==========================================================================

 NEON LDP/STP copy (from framebuffer)                 :    188.3 MB/s
 NEON LDP/STP 2-pass copy (from framebuffer)          :    164.6 MB/s
 NEON LD1/ST1 copy (from framebuffer)                 :     46.8 MB/s
 NEON LD1/ST1 2-pass copy (from framebuffer)          :     44.8 MB/s
 ARM LDP/STP copy (from framebuffer)                  :     93.9 MB/s
 ARM LDP/STP 2-pass copy (from framebuffer)           :     86.0 MB/s

==========================================================================
== Memory latency test                                                  ==
==                                                                      ==
== Average time is measured for random memory accesses in the buffers   ==
== of different sizes. The larger is the buffer, the more significant   ==
== are relative contributions of TLB, L1/L2 cache misses and SDRAM      ==
== accesses. For extremely large buffer sizes we are expecting to see   ==
== page table walk with several requests to SDRAM for almost every      ==
== memory access (though 64MiB is not nearly large enough to experience ==
== this effect to its fullest).                                         ==
==                                                                      ==
== Note 1: All the numbers are representing extra time, which needs to  ==
==         be added to L1 cache latency. The cycle timings for L1 cache ==
==         latency can be usually found in the processor documentation. ==
== Note 2: Dual random read means that we are simultaneously performing ==
==         two independent memory accesses at a time. In the case if    ==
==         the memory subsystem can't handle multiple outstanding       ==
==         requests, dual random read has the same timings as two       ==
==         single reads performed one after another.                    ==
==========================================================================

block size : single random read / dual random read
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    3.5 ns          /     5.9 ns 
    131072 :    5.4 ns          /     8.3 ns 
    262144 :    8.7 ns          /    12.6 ns 
    524288 :   88.3 ns          /   130.2 ns 
   1048576 :  131.4 ns          /   167.2 ns 
   2097152 :  153.2 ns          /   180.2 ns 
   4194304 :  167.2 ns          /   191.2 ns 
   8388608 :  177.0 ns          /   197.8 ns 
  16777216 :  185.7 ns          /   203.9 ns 
  33554432 :  192.8 ns          /   209.5 ns 
  67108864 :  211.8 ns          /   239.7 ns 

Executing tinymembench on a big core:

tinymembench v0.4.9 (simple benchmark for memory throughput and latency)

==========================================================================
== Memory bandwidth tests                                               ==
==                                                                      ==
== Note 1: 1MB = 1000000 bytes                                          ==
== Note 2: Results for 'copy' tests show how many bytes can be          ==
==         copied per second (adding together read and writen           ==
==         bytes would have provided twice higher numbers)              ==
== Note 3: 2-pass copy means that we are using a small temporary buffer ==
==         to first fetch data into it, and only then write it to the   ==
==         destination (source -> L1 cache, L1 cache -> destination)    ==
== Note 4: If sample standard deviation exceeds 0.1%, it is shown in    ==
==         brackets                                                     ==
==========================================================================

 C copy backwards                                     :   3845.2 MB/s
 C copy backwards (32 byte blocks)                    :   3842.1 MB/s
 C copy backwards (64 byte blocks)                    :   3840.9 MB/s
 C copy                                               :   3968.2 MB/s
 C copy prefetched (32 bytes step)                    :   3899.5 MB/s
 C copy prefetched (64 bytes step)                    :   3959.4 MB/s
 C 2-pass copy                                        :   3027.2 MB/s
 C 2-pass copy prefetched (32 bytes step)             :   2806.1 MB/s
 C 2-pass copy prefetched (64 bytes step)             :   2864.0 MB/s (0.2%)
 C fill                                               :   8244.1 MB/s
 C fill (shuffle within 16 byte blocks)               :   8248.0 MB/s
 C fill (shuffle within 32 byte blocks)               :   8247.1 MB/s
 C fill (shuffle within 64 byte blocks)               :   8242.8 MB/s
 ---
 standard memcpy                                      :   3988.4 MB/s
 standard memset                                      :   8239.0 MB/s
 ---
 NEON LDP/STP copy                                    :   3993.3 MB/s
 NEON LDP/STP copy pldl2strm (32 bytes step)          :   3993.2 MB/s
 NEON LDP/STP copy pldl2strm (64 bytes step)          :   3993.5 MB/s
 NEON LDP/STP copy pldl1keep (32 bytes step)          :   3857.9 MB/s
 NEON LDP/STP copy pldl1keep (64 bytes step)          :   3954.3 MB/s (0.1%)
 NEON LD1/ST1 copy                                    :   3993.1 MB/s
 NEON STP fill                                        :   8247.3 MB/s
 NEON STNP fill                                       :   8242.5 MB/s
 ARM LDP/STP copy                                     :   3993.5 MB/s
 ARM STP fill                                         :   8241.5 MB/s
 ARM STNP fill                                        :   8235.3 MB/s

==========================================================================
== Framebuffer read tests.                                              ==
==                                                                      ==
== Many ARM devices use a part of the system memory as the framebuffer, ==
== typically mapped as uncached but with write-combining enabled.       ==
== Writes to such framebuffers are quite fast, but reads are much       ==
== slower and very sensitive to the alignment and the selection of      ==
== CPU instructions which are used for accessing memory.                ==
==                                                                      ==
== Many x86 systems allocate the framebuffer in the GPU memory,         ==
== accessible for the CPU via a relatively slow PCI-E bus. Moreover,    ==
== PCI-E is asymmetric and handles reads a lot worse than writes.       ==
==                                                                      ==
== If uncached framebuffer reads are reasonably fast (at least 100 MB/s ==
== or preferably >300 MB/s), then using the shadow framebuffer layer    ==
== is not necessary in Xorg DDX drivers, resulting in a nice overall    ==
== performance improvement. For example, the xf86-video-fbturbo DDX     ==
== uses this trick.                                                     ==
==========================================================================

 NEON LDP/STP copy (from framebuffer)                 :    346.0 MB/s
 NEON LDP/STP 2-pass copy (from framebuffer)          :    277.8 MB/s
 NEON LD1/ST1 copy (from framebuffer)                 :    346.9 MB/s (0.2%)
 NEON LD1/ST1 2-pass copy (from framebuffer)          :    277.8 MB/s
 ARM LDP/STP copy (from framebuffer)                  :    350.0 MB/s (0.1%)
 ARM LDP/STP 2-pass copy (from framebuffer)           :    282.7 MB/s (0.6%)

==========================================================================
== Memory latency test                                                  ==
==                                                                      ==
== Average time is measured for random memory accesses in the buffers   ==
== of different sizes. The larger is the buffer, the more significant   ==
== are relative contributions of TLB, L1/L2 cache misses and SDRAM      ==
== accesses. For extremely large buffer sizes we are expecting to see   ==
== page table walk with several requests to SDRAM for almost every      ==
== memory access (though 64MiB is not nearly large enough to experience ==
== this effect to its fullest).                                         ==
==                                                                      ==
== Note 1: All the numbers are representing extra time, which needs to  ==
==         be added to L1 cache latency. The cycle timings for L1 cache ==
==         latency can be usually found in the processor documentation. ==
== Note 2: Dual random read means that we are simultaneously performing ==
==         two independent memory accesses at a time. In the case if    ==
==         the memory subsystem can't handle multiple outstanding       ==
==         requests, dual random read has the same timings as two       ==
==         single reads performed one after another.                    ==
==========================================================================

block size : single random read / dual random read
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    5.5 ns          /     9.4 ns 
    131072 :    8.3 ns          /    13.1 ns 
    262144 :   10.4 ns          /    14.7 ns 
    524288 :   12.0 ns          /    15.3 ns 
   1048576 :   14.2 ns          /    17.2 ns 
   2097152 :   92.2 ns          /   136.9 ns 
   4194304 :  133.7 ns          /   172.5 ns 
   8388608 :  158.3 ns          /   190.6 ns 
  16777216 :  171.3 ns          /   199.2 ns 
  33554432 :  178.5 ns          /   203.5 ns 
  67108864 :  183.1 ns          /   205.6 ns 

##########################################################################

OpenSSL 1.1.0g, built on 2 Nov 2017
type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes  16384 bytes
aes-128-cbc     177539.11k   524696.45k  1002830.76k  1338309.63k  1482730.15k  1491779.58k
aes-128-cbc     359446.87k   876767.25k  1322331.99k  1504942.42k  1580441.60k  1585905.66k
aes-192-cbc     168771.72k   466504.68k   817679.19k  1031365.29k  1116127.23k  1121528.49k
aes-192-cbc     332743.97k   789173.25k  1116029.01k  1262224.04k  1318242.99k  1322254.34k
aes-256-cbc     163914.19k   427968.94k   707917.74k   862643.88k   921255.94k   924745.73k
aes-256-cbc     321073.47k   707331.20k   987467.09k  1088269.65k  1130769.07k  1133750.95k

##########################################################################

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,6 CPUs LE)

LE
CPU Freq:  1956  1975  1972  1976  1977  1973  1977  1977  1977

RAM size:    3712 MB,  # CPU hardware threads:   6
RAM usage:   1323 MB,  # Benchmark threads:      6

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:        844    99    832    822  |      19668    99   1692   1677
23:        801    99    827    817  |      19046    99   1662   1648
24:        770    99    839    829  |      18543    99   1642   1628
25:        730    99    845    834  |      17908    99   1609   1594
----------------------------------  | ------------------------------
Avr:              99    836    825  |               99   1651   1637
Tot:              99   1244   1231

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,6 CPUs LE)

LE
CPU Freq:  1987  1989  1989  1989  1989  1989  1989  1990  1990

RAM size:    3712 MB,  # CPU hardware threads:   6
RAM usage:   1323 MB,  # Benchmark threads:      6

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       1565   100   1524   1523  |      24740   100   2111   2110
23:       1495   100   1524   1524  |      24132   100   2089   2088
24:       1438   100   1547   1547  |      23428   100   2058   2056
25:       1401   100   1600   1600  |      22683   100   2019   2019
----------------------------------  | ------------------------------
Avr:             100   1549   1549  |              100   2069   2068
Tot:             100   1809   1808

##########################################################################

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,6 CPUs LE)

LE
CPU Freq:  1983  1988  1989  1989  1989  1989  1989  1989  1989

RAM size:    3712 MB,  # CPU hardware threads:   6
RAM usage:   1323 MB,  # Benchmark threads:      6

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       6268   530   1149   6098  |     126742   531   2035  10809
23:       6190   546   1155   6307  |     123637   532   2009  10698
24:       6022   558   1161   6475  |     120213   532   1983  10551
25:       5881   567   1184   6715  |     116003   530   1946  10324
----------------------------------  | ------------------------------
Avr:             550   1163   6399  |              532   1993  10595
Tot:             541   1578   8497

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,6 CPUs LE)

LE
CPU Freq:  1988  1989  1989  1987  1989  1989  1989  1989  1989

RAM size:    3712 MB,  # CPU hardware threads:   6
RAM usage:   1323 MB,  # Benchmark threads:      6

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       6254   531   1146   6085  |     126971   533   2033  10828
23:       6129   544   1147   6245  |     123702   533   2009  10704
24:       6031   557   1165   6485  |     120183   532   1983  10549
25:       5927   568   1191   6767  |     115927   531   1942  10317
----------------------------------  | ------------------------------
Avr:             550   1162   6396  |              532   1992  10599
Tot:             541   1577   8498

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,6 CPUs LE)

LE
CPU Freq:  1988  1989  1990  1989  1989  1989  1990  1989  1989

RAM size:    3712 MB,  # CPU hardware threads:   6
RAM usage:   1323 MB,  # Benchmark threads:      6

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       6300   533   1151   6129  |     127075   532   2035  10837
23:       6164   545   1152   6280  |     123699   532   2010  10704
24:       6042   558   1163   6497  |     120045   532   1982  10537
25:       5909   568   1188   6747  |     115968   531   1943  10321
----------------------------------  | ------------------------------
Avr:             551   1163   6414  |              532   1992  10599
Tot:             542   1578   8506

Compression: 6399,6396,6414
Decompression: 10595,10599,10599
Total: 8497,8498,8506

##########################################################################

** cpuminer-multi 1.3.3 by tpruvot@github **
BTC donation address: 1FhDPLPpw18X4srecguG3MxJYe4a1JsZnd (tpruvot)

[2019-02-19 00:41:04] 6 miner threads started, using 'scrypt' algorithm.
[2019-02-19 00:41:05] CPU #2: 2.15 kH/s
[2019-02-19 00:41:05] CPU #5: 2.15 kH/s
[2019-02-19 00:41:05] CPU #4: 2.11 kH/s
[2019-02-19 00:41:05] CPU #3: 2.09 kH/s
[2019-02-19 00:41:05] CPU #1: 1.93 kH/s
[2019-02-19 00:41:05] CPU #0: 1.86 kH/s
[2019-02-19 00:41:09] Total: 12.44 kH/s

Total Scores: 12.44

##########################################################################

Testing clockspeeds again. System health now:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
00:45:45: 1992/1992MHz  1.05   0%   0%   0%   0%   0%   0%  27.6°C

Trying to check cpufreq OPP for A53 cluster (cpu0-cpu1):

Cpufreq OPP: 1992    Measured: 1970.056/1978.435/1978.556
Cpufreq OPP: 1896    Measured: 1883.328/1883.130/1884.009
Cpufreq OPP: 1704    Measured: 1689.739/1692.166/1690.305
Cpufreq OPP: 1608    Measured: 1594.338/1595.106/1593.806
Cpufreq OPP: 1512    Measured: 1497.942/1499.699/1493.766
Cpufreq OPP: 1398    Measured: 1382.134/1384.831/1384.520
Cpufreq OPP: 1200    Measured: 1185.946/1185.796/1186.736
Cpufreq OPP: 1000    Measured: 986.563/984.788/986.327
Cpufreq OPP:  667    Measured: 653.672/654.464/653.389
Cpufreq OPP:  500    Measured: 485.413/484.108/485.374
Cpufreq OPP:  250    Measured: 236.775/239.815/235.749
Cpufreq OPP:  100    Measured: 86.174/87.185/86.526

Trying to check cpufreq OPP for A73 cluster (cpu2-cpu5):

Cpufreq OPP: 1992    Measured: 1989.874/1989.947/1989.800
Cpufreq OPP: 1908    Measured: 1905.247/1906.192/1906.327
Cpufreq OPP: 1800    Measured: 1797.465/1797.906/1797.445
Cpufreq OPP: 1704    Measured: 1701.961/1702.374/1701.836
Cpufreq OPP: 1608    Measured: 1605.977/1606.557/1606.137
Cpufreq OPP: 1512    Measured: 1509.923/1510.276/1510.364
Cpufreq OPP: 1398    Measured: 1395.894/1395.683/1396.241
Cpufreq OPP: 1200    Measured: 1197.938/1198.174/1197.952
Cpufreq OPP: 1000    Measured: 998.205/998.181/998.326
Cpufreq OPP:  667    Measured: 664.689/665.064/664.689
Cpufreq OPP:  500    Measured: 498.574/498.023/498.727
Cpufreq OPP:  250    Measured: 247.791/247.387/247.147
Cpufreq OPP:  100    Measured: 98.270/97.480/97.406

##########################################################################

System health while running tinymembench:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
00:17:52: 1992/1992MHz  1.07   3%   1%   2%   0%   0%   0%  29.0°C
00:19:52: 1992/1992MHz  1.88  16%   0%  16%   0%   0%   0%  28.2°C
00:21:52: 1992/1992MHz  1.99  16%   0%  16%   0%   0%   0%  28.0°C
00:23:52: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  27.8°C
00:25:52: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  29.9°C

System health while running OpenSSL benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
00:27:11: 1992/1992MHz  2.00  13%   0%  13%   0%   0%   0%  29.5°C
00:27:21: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  27.8°C
00:27:31: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  34.0°C
00:27:41: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  33.1°C
00:27:51: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  27.9°C
00:28:01: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  27.8°C
00:28:11: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  34.1°C
00:28:21: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  33.9°C
00:28:31: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  27.9°C
00:28:41: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  33.3°C
00:28:51: 1992/1992MHz  2.00  16%   0%  16%   0%   0%   0%  33.9°C

System health while running 7-zip single core benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
00:28:59: 1992/1992MHz  2.00  14%   0%  13%   0%   0%   0%  31.5°C
00:29:59: 1992/1992MHz  4.07  16%   0%  16%   0%   0%   0%  27.9°C
00:30:59: 1992/1992MHz  4.79  16%   0%  16%   0%   0%   0%  27.9°C
00:31:59: 1992/1992MHz  5.15  16%   0%  16%   0%   0%   0%  27.8°C
00:32:59: 1992/1992MHz  4.93  16%   0%  16%   0%   0%   0%  27.8°C
00:33:59: 1992/1992MHz  4.63  16%   0%  16%   0%   0%   0%  27.9°C
00:34:59: 1992/1992MHz  5.07  16%   0%  16%   0%   0%   0%  31.3°C
00:35:59: 1992/1992MHz  5.81  16%   0%  16%   0%   0%   0%  32.5°C
00:36:59: 1992/1992MHz  5.75  16%   0%  16%   0%   0%   0%  32.6°C
00:37:59: 1992/1992MHz  5.31  16%   0%  16%   0%   0%   0%  31.5°C

System health while running 7-zip multi core benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
00:38:30: 1992/1992MHz  5.70  15%   0%  14%   0%   0%   0%  31.7°C
00:38:50: 1992/1992MHz  6.20  78%   1%  77%   0%   0%   0%  38.2°C
00:39:11: 1992/1992MHz  6.66  88%   1%  86%   0%   0%   0%  38.5°C
00:39:31: 1992/1992MHz  7.02  83%   1%  81%   0%   0%   0%  37.1°C
00:39:51: 1992/1992MHz  6.60  91%   1%  89%   0%   0%   0%  42.6°C
00:40:12: 1992/1992MHz  6.84  89%   1%  87%   0%   0%   0%  42.9°C
00:40:32: 1992/1992MHz  6.57  77%   1%  76%   0%   0%   0%  39.6°C
00:40:52: 1992/1992MHz  7.05  88%   1%  86%   0%   0%   0%  39.8°C

System health while running cpuminer:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
00:41:05: 1992/1992MHz  7.04  22%   0%  21%   0%   0%   0%  36.3°C
00:41:25: 1992/1992MHz  5.38  20%   0%  20%   0%   0%   0%  29.7°C
00:41:45: 1992/1992MHz  4.14   0%   0%   0%   0%   0%   0%  29.2°C
00:42:05: 1992/1992MHz  3.24   0%   0%   0%   0%   0%   0%  29.0°C
00:42:25: 1992/1992MHz  2.61   0%   0%   0%   0%   0%   0%  28.7°C
00:42:45: 1992/1992MHz  2.15   0%   0%   0%   0%   0%   0%  28.8°C
00:43:05: 1992/1992MHz  1.82   0%   0%   0%   0%   0%   0%  28.5°C
00:43:25: 1992/1992MHz  1.59   0%   0%   0%   0%   0%   0%  28.4°C
00:43:45: 1992/1992MHz  1.42   0%   0%   0%   0%   0%   0%  28.2°C
00:44:05: 1992/1992MHz  1.30   0%   0%   0%   0%   0%   0%  28.1°C
00:44:25: 1992/1992MHz  1.21   0%   0%   0%   0%   0%   0%  28.2°C
00:44:45: 1992/1992MHz  1.15   0%   0%   0%   0%   0%   0%  27.9°C
00:45:05: 1992/1992MHz  1.11   0%   0%   0%   0%   0%   0%  27.8°C
00:45:25: 1992/1992MHz  1.08   0%   0%   0%   0%   0%   0%  27.7°C
00:45:45: 1992/1992MHz  1.05   0%   0%   0%   0%   0%   0%  27.6°C

##########################################################################

dmesg output while running the benchmarks:

[  284.825035] random: crng init done
[  284.825042] random: 7 urandom warning(s) missed due to ratelimiting
[  611.321208] fb: osd[0] enable: 0 (kworker/0:2)

##########################################################################

Linux 4.9.156-14 (odroid) 	02/19/19 	_aarch64_	(6 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          18.42    0.00    0.38    0.02    0.00   81.18

Device             tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
mmcblk0           2.11        65.84         8.43     123415      15812
mmcblk0rpmb       0.00         0.01         0.00         16          0
mmcblk0boot1      0.06         0.23         0.00        432          0
mmcblk0boot0      0.06         0.23         0.00        432          0

              total        used        free      shared  buff/cache   available
Mem:           3.6G        148M        3.3G        3.4M        146M        3.4G
Swap:            0B          0B          0B



Architecture:        aarch64
Byte Order:          Little Endian
CPU(s):              6
On-line CPU(s) list: 0-5
Thread(s) per core:  1
Core(s) per socket:  3
Socket(s):           2
Vendor ID:           ARM
Model:               4
Model name:          Cortex-A53
Stepping:            r0p4
CPU max MHz:         1992.0000
CPU min MHz:         100.0000
BogoMIPS:            48.00
Flags:               fp asimd evtstrm aes pmull sha1 sha2 crc32
