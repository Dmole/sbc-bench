sbc-bench v0.9.8 Libre Computer AML-S912-PC (Wed, 15 Jun 2022 09:00:49 +0200)

Distributor ID:	Debian
Description:	Debian GNU/Linux 11 (bullseye)
Release:	11
Codename:	bullseye
Armbian info:   Aml s912, meson-g12b, meson64, 22.08.0-trunk, https://github.com/armbian/build.git

/usr/bin/gcc (Debian 10.2.1-6) 10.2.1 20210110

Uptime: 09:00:49 up 22 min,  1 user,  load average: 3.09, 1.82, 1.07

Linux 5.15.46-flippy-73+o (armbian) 	06/15/22 	_aarch64_	(8 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.76    0.01    0.84    6.36    0.00   92.03

Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
mmcblk1           8.77       289.28       273.88       743.26     397798     376622    1022068
mmcblk2           0.14         3.04         0.00         0.00       4180          0          0
zram0             0.43         1.72         0.00         0.00       2360          4          0
zram1             0.88         0.56        18.95         0.00        768      26060          0
zram2             0.69         1.57         1.38         0.00       2160       1896          0

               total        used        free      shared  buff/cache   available
Mem:           1.8Gi       173Mi       1.5Gi       1.0Mi        64Mi       1.5Gi
Swap:          904Mi          0B       904Mi

Filename				Type		Size	Used	Priority
/dev/zram0                             	partition	926468	0	5

##########################################################################

Checking cpufreq OPP for cpu0-cpu3 (Cortex-A53):

Cpufreq OPP: 1512    Measured: 1412 (1412.739/1412.337/1412.183)     (-6.6%)
Cpufreq OPP: 1200    Measured: 1196 (1197.313/1196.814/1196.273)
Cpufreq OPP: 1000    Measured:  996    (997.061/996.965/996.172)
Cpufreq OPP:  667    Measured:  663    (663.475/663.269/662.631)
Cpufreq OPP:  500    Measured:  496    (497.122/496.801/496.783)
Cpufreq OPP:  250    Measured:  246    (247.240/246.829/246.531)     (-1.6%)
Cpufreq OPP:  100    Measured:   96       (97.027/96.943/96.115)     (-4.0%)

Checking cpufreq OPP for cpu4-cpu7 (Cortex-A53):

Cpufreq OPP: 1000    Measured:  997    (997.651/997.603/997.542)
Cpufreq OPP:  667    Measured:  664    (664.269/664.209/664.122)
Cpufreq OPP:  500    Measured:  497    (497.782/497.671/497.630)
Cpufreq OPP:  250    Measured:  247    (248.004/247.851/247.721)     (-1.2%)
Cpufreq OPP:  100    Measured:   97       (97.795/97.719/97.563)     (-3.0%)

##########################################################################

Hardware sensors:

scpi_sensors-isa-0000
aml_thermal:  +49.0 C  

tcpm_source_psy_0_0022-i2c-0-22
in0:           0.00 V  (min =  +0.00 V, max =  +0.00 V)
curr1:         0.00 A  (max =  +0.00 A)

##########################################################################

Executing benchmark on cpu0 (Cortex-A53):

tinymembench v0.4.9 (simple benchmark for memory throughput and latency)

==========================================================================
== Memory bandwidth tests                                               ==
==                                                                      ==
== Note 1: 1MB = 1000000 bytes                                          ==
== Note 2: Results for 'copy' tests show how many bytes can be          ==
==         copied per second (adding together read and writen           ==
==         bytes would have provided twice higher numbers)              ==
== Note 3: 2-pass copy means that we are using a small temporary buffer ==
==         to first fetch data into it, and only then write it to the   ==
==         destination (source -> L1 cache, L1 cache -> destination)    ==
== Note 4: If sample standard deviation exceeds 0.1%, it is shown in    ==
==         brackets                                                     ==
==========================================================================

 C copy backwards                                     :   1622.6 MB/s (1.5%)
 C copy backwards (32 byte blocks)                    :   1627.8 MB/s (0.7%)
 C copy backwards (64 byte blocks)                    :   1648.9 MB/s (0.7%)
 C copy                                               :   1596.0 MB/s (0.8%)
 C copy prefetched (32 bytes step)                    :   1198.9 MB/s
 C copy prefetched (64 bytes step)                    :   1422.5 MB/s
 C 2-pass copy                                        :   1362.5 MB/s
 C 2-pass copy prefetched (32 bytes step)             :    932.0 MB/s
 C 2-pass copy prefetched (64 bytes step)             :    844.9 MB/s
 C fill                                               :   5164.1 MB/s
 C fill (shuffle within 16 byte blocks)               :   5162.3 MB/s
 C fill (shuffle within 32 byte blocks)               :   5164.1 MB/s
 C fill (shuffle within 64 byte blocks)               :   5163.8 MB/s
 ---
 standard memcpy                                      :   1654.1 MB/s (0.2%)
 standard memset                                      :   5166.1 MB/s
 ---
 NEON LDP/STP copy                                    :   1656.4 MB/s (0.5%)
 NEON LDP/STP copy pldl2strm (32 bytes step)          :   1078.5 MB/s (0.4%)
 NEON LDP/STP copy pldl2strm (64 bytes step)          :   1403.8 MB/s
 NEON LDP/STP copy pldl1keep (32 bytes step)          :   1781.0 MB/s
 NEON LDP/STP copy pldl1keep (64 bytes step)          :   1789.6 MB/s
 NEON LD1/ST1 copy                                    :   1655.4 MB/s (0.4%)
 NEON STP fill                                        :   5165.3 MB/s
 NEON STNP fill                                       :   3863.1 MB/s (0.6%)
 ARM LDP/STP copy                                     :   1650.1 MB/s (0.3%)
 ARM STP fill                                         :   5165.7 MB/s
 ARM STNP fill                                        :   3876.4 MB/s (0.9%)

==========================================================================
== Framebuffer read tests.                                              ==
==                                                                      ==
== Many ARM devices use a part of the system memory as the framebuffer, ==
== typically mapped as uncached but with write-combining enabled.       ==
== Writes to such framebuffers are quite fast, but reads are much       ==
== slower and very sensitive to the alignment and the selection of      ==
== CPU instructions which are used for accessing memory.                ==
==                                                                      ==
== Many x86 systems allocate the framebuffer in the GPU memory,         ==
== accessible for the CPU via a relatively slow PCI-E bus. Moreover,    ==
== PCI-E is asymmetric and handles reads a lot worse than writes.       ==
==                                                                      ==
== If uncached framebuffer reads are reasonably fast (at least 100 MB/s ==
== or preferably >300 MB/s), then using the shadow framebuffer layer    ==
== is not necessary in Xorg DDX drivers, resulting in a nice overall    ==
== performance improvement. For example, the xf86-video-fbturbo DDX     ==
== uses this trick.                                                     ==
==========================================================================

 NEON LDP/STP copy (from framebuffer)                 :    179.0 MB/s
 NEON LDP/STP 2-pass copy (from framebuffer)          :    146.5 MB/s
 NEON LD1/ST1 copy (from framebuffer)                 :     39.7 MB/s
 NEON LD1/ST1 2-pass copy (from framebuffer)          :     38.0 MB/s
 ARM LDP/STP copy (from framebuffer)                  :     82.6 MB/s
 ARM LDP/STP 2-pass copy (from framebuffer)           :     75.3 MB/s

==========================================================================
== Memory latency test                                                  ==
==                                                                      ==
== Average time is measured for random memory accesses in the buffers   ==
== of different sizes. The larger is the buffer, the more significant   ==
== are relative contributions of TLB, L1/L2 cache misses and SDRAM      ==
== accesses. For extremely large buffer sizes we are expecting to see   ==
== page table walk with several requests to SDRAM for almost every      ==
== memory access (though 64MiB is not nearly large enough to experience ==
== this effect to its fullest).                                         ==
==                                                                      ==
== Note 1: All the numbers are representing extra time, which needs to  ==
==         be added to L1 cache latency. The cycle timings for L1 cache ==
==         latency can be usually found in the processor documentation. ==
== Note 2: Dual random read means that we are simultaneously performing ==
==         two independent memory accesses at a time. In the case if    ==
==         the memory subsystem can't handle multiple outstanding       ==
==         requests, dual random read has the same timings as two       ==
==         single reads performed one after another.                    ==
==========================================================================

block size : single random read / dual random read, [MADV_NOHUGEPAGE]
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    4.1 ns          /     7.4 ns 
    131072 :    6.4 ns          /    10.8 ns 
    262144 :    8.4 ns          /    13.7 ns 
    524288 :   95.0 ns          /   148.8 ns 
   1048576 :  149.9 ns          /   197.4 ns 
   2097152 :  178.1 ns          /   213.4 ns 
   4194304 :  194.9 ns          /   220.0 ns 
   8388608 :  204.8 ns          /   223.0 ns 
  16777216 :  209.0 ns          /   224.6 ns 
  33554432 :  211.1 ns          /   224.9 ns 
  67108864 :  222.4 ns          /   246.3 ns 

block size : single random read / dual random read, [MADV_HUGEPAGE]
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    4.1 ns          /     7.4 ns 
    131072 :    6.4 ns          /    10.8 ns 
    262144 :    8.4 ns          /    13.7 ns 
    524288 :   95.7 ns          /   148.9 ns 
   1048576 :  149.9 ns          /   197.4 ns 
   2097152 :  177.4 ns          /   212.3 ns 
   4194304 :  189.7 ns          /   217.2 ns 
   8388608 :  197.3 ns          /   219.2 ns 
  16777216 :  199.9 ns          /   220.0 ns 
  33554432 :  203.1 ns          /   220.4 ns 
  67108864 :  203.9 ns          /   220.6 ns 

Executing benchmark on cpu4 (Cortex-A53):

tinymembench v0.4.9 (simple benchmark for memory throughput and latency)

==========================================================================
== Memory bandwidth tests                                               ==
==                                                                      ==
== Note 1: 1MB = 1000000 bytes                                          ==
== Note 2: Results for 'copy' tests show how many bytes can be          ==
==         copied per second (adding together read and writen           ==
==         bytes would have provided twice higher numbers)              ==
== Note 3: 2-pass copy means that we are using a small temporary buffer ==
==         to first fetch data into it, and only then write it to the   ==
==         destination (source -> L1 cache, L1 cache -> destination)    ==
== Note 4: If sample standard deviation exceeds 0.1%, it is shown in    ==
==         brackets                                                     ==
==========================================================================

 C copy backwards                                     :   1529.5 MB/s (1.6%)
 C copy backwards (32 byte blocks)                    :   1538.2 MB/s (1.5%)
 C copy backwards (64 byte blocks)                    :   1540.0 MB/s (1.7%)
 C copy                                               :   1519.6 MB/s (1.1%)
 C copy prefetched (32 bytes step)                    :   1138.0 MB/s (0.4%)
 C copy prefetched (64 bytes step)                    :   1352.3 MB/s
 C 2-pass copy                                        :   1178.9 MB/s
 C 2-pass copy prefetched (32 bytes step)             :    794.9 MB/s
 C 2-pass copy prefetched (64 bytes step)             :    771.7 MB/s
 C fill                                               :   4652.4 MB/s
 C fill (shuffle within 16 byte blocks)               :   4651.8 MB/s
 C fill (shuffle within 32 byte blocks)               :   4646.4 MB/s
 C fill (shuffle within 64 byte blocks)               :   4647.7 MB/s
 ---
 standard memcpy                                      :   1586.4 MB/s
 standard memset                                      :   4651.8 MB/s
 ---
 NEON LDP/STP copy                                    :   1546.4 MB/s (0.7%)
 NEON LDP/STP copy pldl2strm (32 bytes step)          :   1023.0 MB/s (1.0%)
 NEON LDP/STP copy pldl2strm (64 bytes step)          :   1338.2 MB/s (0.1%)
 NEON LDP/STP copy pldl1keep (32 bytes step)          :   1670.1 MB/s (0.2%)
 NEON LDP/STP copy pldl1keep (64 bytes step)          :   1674.8 MB/s
 NEON LD1/ST1 copy                                    :   1563.1 MB/s (0.5%)
 NEON STP fill                                        :   4652.5 MB/s
 NEON STNP fill                                       :   3592.1 MB/s
 ARM LDP/STP copy                                     :   1557.6 MB/s (0.4%)
 ARM STP fill                                         :   4652.7 MB/s
 ARM STNP fill                                        :   3605.0 MB/s (0.2%)

==========================================================================
== Framebuffer read tests.                                              ==
==                                                                      ==
== Many ARM devices use a part of the system memory as the framebuffer, ==
== typically mapped as uncached but with write-combining enabled.       ==
== Writes to such framebuffers are quite fast, but reads are much       ==
== slower and very sensitive to the alignment and the selection of      ==
== CPU instructions which are used for accessing memory.                ==
==                                                                      ==
== Many x86 systems allocate the framebuffer in the GPU memory,         ==
== accessible for the CPU via a relatively slow PCI-E bus. Moreover,    ==
== PCI-E is asymmetric and handles reads a lot worse than writes.       ==
==                                                                      ==
== If uncached framebuffer reads are reasonably fast (at least 100 MB/s ==
== or preferably >300 MB/s), then using the shadow framebuffer layer    ==
== is not necessary in Xorg DDX drivers, resulting in a nice overall    ==
== performance improvement. For example, the xf86-video-fbturbo DDX     ==
== uses this trick.                                                     ==
==========================================================================

 NEON LDP/STP copy (from framebuffer)                 :    174.0 MB/s
 NEON LDP/STP 2-pass copy (from framebuffer)          :    144.6 MB/s
 NEON LD1/ST1 copy (from framebuffer)                 :     39.1 MB/s
 NEON LD1/ST1 2-pass copy (from framebuffer)          :     37.2 MB/s
 ARM LDP/STP copy (from framebuffer)                  :     80.8 MB/s
 ARM LDP/STP 2-pass copy (from framebuffer)           :     73.5 MB/s

==========================================================================
== Memory latency test                                                  ==
==                                                                      ==
== Average time is measured for random memory accesses in the buffers   ==
== of different sizes. The larger is the buffer, the more significant   ==
== are relative contributions of TLB, L1/L2 cache misses and SDRAM      ==
== accesses. For extremely large buffer sizes we are expecting to see   ==
== page table walk with several requests to SDRAM for almost every      ==
== memory access (though 64MiB is not nearly large enough to experience ==
== this effect to its fullest).                                         ==
==                                                                      ==
== Note 1: All the numbers are representing extra time, which needs to  ==
==         be added to L1 cache latency. The cycle timings for L1 cache ==
==         latency can be usually found in the processor documentation. ==
== Note 2: Dual random read means that we are simultaneously performing ==
==         two independent memory accesses at a time. In the case if    ==
==         the memory subsystem can't handle multiple outstanding       ==
==         requests, dual random read has the same timings as two       ==
==         single reads performed one after another.                    ==
==========================================================================

block size : single random read / dual random read, [MADV_NOHUGEPAGE]
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    5.8 ns          /    10.4 ns 
    131072 :    9.0 ns          /    15.3 ns 
    262144 :   11.8 ns          /    19.3 ns 
    524288 :   99.1 ns          /   151.0 ns 
   1048576 :  151.7 ns          /   196.3 ns 
   2097152 :  180.2 ns          /   211.5 ns 
   4194304 :  196.7 ns          /   223.1 ns 
   8388608 :  206.9 ns          /   229.6 ns 
  16777216 :  213.4 ns          /   233.5 ns 
  33554432 :  218.3 ns          /   237.8 ns 
  67108864 :  235.3 ns          /   267.6 ns 

block size : single random read / dual random read, [MADV_HUGEPAGE]
      1024 :    0.0 ns          /     0.0 ns 
      2048 :    0.0 ns          /     0.0 ns 
      4096 :    0.0 ns          /     0.0 ns 
      8192 :    0.0 ns          /     0.0 ns 
     16384 :    0.0 ns          /     0.0 ns 
     32768 :    0.0 ns          /     0.0 ns 
     65536 :    5.8 ns          /    10.4 ns 
    131072 :    9.0 ns          /    15.3 ns 
    262144 :   11.8 ns          /    19.3 ns 
    524288 :   99.2 ns          /   150.9 ns 
   1048576 :  151.7 ns          /   196.2 ns 
   2097152 :  178.9 ns          /   210.0 ns 
   4194304 :  192.8 ns          /   214.7 ns 
   8388608 :  199.6 ns          /   215.7 ns 
  16777216 :  203.0 ns          /   217.2 ns 
  33554432 :  204.7 ns          /   217.5 ns 
  67108864 :  205.5 ns          /   217.7 ns 

##########################################################################

Executing ramlat on cpu0 (Cortex-A53), results in ns:

       size:  1x32  2x32  1x64  2x64 1xPTR 2xPTR 4xPTR 8xPTR
         4k: 2.833 2.832 2.125 2.125 2.124 2.124 2.921 5.930 
         8k: 2.832 2.833 2.124 2.124 2.125 2.124 2.921 5.931 
        16k: 2.833 2.833 2.124 2.125 2.125 2.125 2.922 5.935 
        32k: 2.840 2.838 2.130 2.130 2.130 2.129 2.927 5.941 
        64k: 15.92 16.92 15.17 16.42 15.15 16.55 24.76 47.41 
       128k: 17.96 18.59 17.20 18.11 17.19 18.15 27.34 55.04 
       256k: 35.93 48.11 35.33 45.74 35.71 45.99 83.94 161.0 
       512k: 165.8 143.5 165.7 140.0 165.6 140.8 209.8 417.9 
      1024k: 179.4 147.1 179.5 146.8 179.4 146.9 209.9 424.3 
      2048k: 180.2 149.1 180.2 147.6 180.2 147.6 210.2 425.5 
      4096k: 216.5 182.2 216.5 182.1 216.5 188.7 215.1 439.8 
      8192k: 218.2 183.9 218.2 184.0 203.0 190.5 220.3 448.6 
     16384k: 219.4 196.1 219.7 196.2 219.6 200.7 228.7 461.0 

Executing ramlat on cpu4 (Cortex-A53), results in ns:

       size:  1x32  2x32  1x64  2x64 1xPTR 2xPTR 4xPTR 8xPTR
         4k: 4.010 4.010 3.008 3.008 3.008 3.008 4.135 8.397 
         8k: 4.011 4.013 3.008 3.008 3.008 3.008 4.136 8.397 
        16k: 4.011 4.010 3.008 3.008 3.008 3.008 4.136 8.397 
        32k: 4.021 4.022 3.017 3.016 3.017 3.017 4.150 8.415 
        64k: 22.95 24.56 22.47 24.11 22.47 24.22 32.44 63.33 
       128k: 24.30 25.69 23.77 24.92 23.77 25.02 38.83 77.61 
       256k: 61.58 79.64 61.54 77.85 61.37 78.35 132.2 254.5 
       512k: 182.6 161.1 182.8 159.8 180.8 161.3 233.2 468.6 
      1024k: 214.7 177.6 214.6 177.3 214.7 183.7 242.4 486.1 
      2048k: 215.6 179.0 215.5 179.2 215.3 185.5 240.0 485.2 
      4096k: 223.3 228.2 223.3 228.3 223.4 227.8 245.1 512.6 
      8192k: 225.8 233.1 225.8 233.1 225.9 233.1 254.8 529.9 
     16384k: 227.7 235.7 227.7 235.8 227.8 223.6 260.8 540.2 

##########################################################################

Executing benchmark on each cluster individually

OpenSSL 1.1.1n, built on 15 Mar 2022
type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes  16384 bytes
aes-128-cbc      91894.56k   292088.66k   624663.30k   911398.57k  1051563.35k  1062846.46k (Cortex-A53)
aes-128-cbc      64902.83k   206266.33k   441254.31k   643689.47k   742596.61k   750398.12k (Cortex-A53)
aes-192-cbc      87887.43k   265034.84k   521608.02k   709860.35k   793032.02k   798932.99k (Cortex-A53)
aes-192-cbc      62068.83k   187160.64k   368399.53k   501379.07k   560166.23k   564598.10k (Cortex-A53)
aes-256-cbc      85877.59k   247370.54k   458134.70k   597282.82k   655108.78k   659286.70k (Cortex-A53)
aes-256-cbc      60676.50k   174884.74k   323577.43k   421881.17k   462752.43k   465715.20k (Cortex-A53)

##########################################################################

Executing benchmark single-threaded on cpu0 (Cortex-A53)

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: 64000000 - - - - - - - -

RAM size:    1809 MB,  # CPU hardware threads:   8
RAM usage:    435 MB,  # Benchmark threads:      1

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:        780   100    760    759  |      15201   100   1298   1298
23:        725   100    739    739  |      14873   100   1288   1287
24:        684   100    736    736  |      14535   100   1277   1276
25:        652   100    745    745  |      14136   100   1259   1258
----------------------------------  | ------------------------------
Avr:             100    745    745  |              100   1280   1280
Tot:             100   1013   1012

Executing benchmark single-threaded on cpu4 (Cortex-A53)

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: 64000000 - 64000000 - - - - - -

RAM size:    1809 MB,  # CPU hardware threads:   8
RAM usage:    435 MB,  # Benchmark threads:      1

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:        615   100    599    599  |      10968   100    937    936
23:        570   100    582    582  |      10768   100    932    932
24:        537   100    578    578  |      10556   100    927    927
25:        515   100    588    588  |      10295   100    916    916
----------------------------------  | ------------------------------
Avr:             100    587    587  |              100    928    928
Tot:             100    757    757

##########################################################################

Executing benchmark 3 times multi-threaded on CPUs 0-7

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: 64000000 64000000 64000000 - - - - - -

RAM size:    1809 MB,  # CPU hardware threads:   8
RAM usage:   1765 MB,  # Benchmark threads:      8

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       4475   689    632   4354  |      92508   711   1110   7891
23:       4301   705    622   4383  |      90479   710   1102   7830
24:       4255   737    621   4575  |      88591   711   1094   7775
25:       3302   698    540   3770  |      86054   713   1075   7658
----------------------------------  | ------------------------------
Avr:             707    604   4271  |              711   1095   7789
Tot:             709    849   6030

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: - - - - - - - - -

RAM size:    1809 MB,  # CPU hardware threads:   8
RAM usage:   1765 MB,  # Benchmark threads:      8

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       4504   695    631   4382  |      92320   710   1108   7874
23:       4328   710    621   4410  |      90623   712   1102   7842
24:       4175   722    621   4490  |      88652   712   1094   7781
25:       2579   641    459   2945  |      85741   710   1075   7631
----------------------------------  | ------------------------------
Avr:             692    583   4057  |              711   1095   7782
Tot:             702    839   5919

7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C,Utf16=off,HugeFiles=on,64 bits,8 CPUs LE)

LE
CPU Freq: 64000000 - 64000000 - - - - - -

RAM size:    1809 MB,  # CPU hardware threads:   8
RAM usage:   1765 MB,  # Benchmark threads:      8

                       Compressing  |                  Decompressing
Dict     Speed Usage    R/U Rating  |      Speed Usage    R/U Rating
         KiB/s     %   MIPS   MIPS  |      KiB/s     %   MIPS   MIPS

22:       4492   692    631   4371  |      92247   710   1108   7868
23:       4330   709    622   4412  |      90562   712   1101   7837
24:       4187   723    623   4502  |      88723   712   1094   7787
25:       3095   678    521   3534  |      86272   713   1076   7678
----------------------------------  | ------------------------------
Avr:             701    599   4205  |              712   1095   7793
Tot:             706    847   5999

Compression: 4271,4057,4205
Decompression: 7789,7782,7793
Total: 6030,5919,5999

##########################################################################

Testing maximum cpufreq again, still under full load. System health now:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
09:37:44: 1512/1000MHz  7.33  90%   4%  85%   0%   0%   0%  71.0°C

Checking cpufreq OPP for cpu0-cpu3 (Cortex-A53):

Cpufreq OPP: 1512    Measured: 1412 (1412.956/1412.214/1412.059)     (-6.6%)

Checking cpufreq OPP for cpu4-cpu7 (Cortex-A53):

Cpufreq OPP: 1000    Measured:  997    (997.603/997.603/997.567)

##########################################################################

Hardware sensors:

scpi_sensors-isa-0000
aml_thermal:  +63.0 C  

tcpm_source_psy_0_0022-i2c-0-22
in0:           0.00 V  (min =  +0.00 V, max =  +0.00 V)
curr1:         0.00 A  (max =  +0.00 A)

##########################################################################

Thermal source: /sys/devices/virtual/thermal/thermal_zone0/ (cpu-thermal)
                (Armbian wants to use /sys/class/hwmon/hwmon0 instead, that
                zone is named scpi_sensors. Please check and if wrong
                file a bug here: https://github.com/armbian/build/issues/)

System health while running tinymembench:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
09:01:39: 1512/1000MHz  3.47   8%   0%   1%   0%   6%   0%  51.0°C
09:02:59: 1512/1000MHz  1.65  12%   0%  12%   0%   0%   0%  53.0°C
09:04:19: 1512/1000MHz  1.17  12%   0%  12%   0%   0%   0%  52.0°C
09:05:39: 1512/1000MHz  1.09  12%   0%  12%   0%   0%   0%  52.0°C
09:06:59: 1512/1000MHz  1.02  12%   0%  12%   0%   0%   0%  52.0°C
09:08:19: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  53.0°C
09:09:39: 1512/1000MHz  1.04  12%   0%  12%   0%   0%   0%  54.0°C
09:10:59: 1512/1000MHz  1.07  12%   0%  12%   0%   0%   0%  53.0°C
09:12:20: 1512/1000MHz  1.02  12%   0%  12%   0%   0%   0%  55.0°C
09:13:40: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  56.0°C
09:15:00: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C
09:16:20: 1512/1000MHz  1.07  12%   0%  12%   0%   0%   0%  54.0°C
09:17:40: 1512/1000MHz  1.02  12%   0%  12%   0%   0%   0%  54.0°C
09:19:00: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C
09:20:20: 1512/1000MHz  1.06  12%   0%  12%   0%   0%   0%  54.0°C

System health while running ramlat:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
09:21:35: 1512/1000MHz  1.02  10%   0%   6%   0%   3%   0%  54.0°C
09:21:41: 1512/1000MHz  1.01  12%   0%  12%   0%   0%   0%  54.0°C
09:21:48: 1512/1000MHz  1.01  12%   0%  12%   0%   0%   0%  54.0°C
09:21:54: 1512/1000MHz  1.01  12%   0%  12%   0%   0%   0%  54.0°C
09:22:00: 1512/1000MHz  1.01  12%   0%  12%   0%   0%   0%  55.0°C
09:22:06: 1512/1000MHz  1.01  12%   0%  12%   0%   0%   0%  54.0°C
09:22:12: 1512/1000MHz  1.01  12%   0%  12%   0%   0%   0%  54.0°C
09:22:18: 1512/1000MHz  1.01  12%   0%  12%   0%   0%   0%  54.0°C
09:22:24: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C
09:22:30: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C

System health while running OpenSSL benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
09:22:31: 1512/1000MHz  1.00  10%   0%   6%   0%   3%   0%  55.0°C
09:22:47: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C
09:23:04: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C
09:23:20: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  55.0°C
09:23:36: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C
09:23:52: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  54.0°C
09:24:08: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  55.0°C

System health while running 7-zip single core benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
09:24:20: 1512/1000MHz  1.00  10%   0%   6%   0%   3%   0%  56.0°C
09:24:35: 1512/1000MHz  1.00  12%   0%  12%   0%   0%   0%  55.0°C
09:24:50: 1512/1000MHz  1.07  12%   0%  12%   0%   0%   0%  55.0°C
09:25:05: 1512/1000MHz  1.12  12%   0%  12%   0%   0%   0%  55.0°C
09:25:20: 1512/1000MHz  1.24  12%   0%  12%   0%   0%   0%  55.0°C
09:25:35: 1512/1000MHz  1.19  12%   0%  12%   0%   0%   0%  56.0°C
09:25:50: 1512/1000MHz  1.14  12%   0%  12%   0%   0%   0%  56.0°C
09:26:05: 1512/1000MHz  1.11  12%   0%  12%   0%   0%   0%  56.0°C
09:26:21: 1512/1000MHz  1.15  12%   0%  12%   0%   0%   0%  56.0°C
09:26:36: 1512/1000MHz  1.12  12%   0%  12%   0%   0%   0%  56.0°C
09:26:51: 1512/1000MHz  1.09  12%   0%  12%   0%   0%   0%  56.0°C
09:27:06: 1512/1000MHz  1.07  12%   0%  12%   0%   0%   0%  56.0°C
09:27:21: 1512/1000MHz  1.06  12%   0%  12%   0%   0%   0%  56.0°C
09:27:36: 1512/1000MHz  1.04  12%   0%  12%   0%   0%   0%  56.0°C
09:27:51: 1512/1000MHz  1.10  12%   0%  12%   0%   0%   0%  56.0°C
09:28:06: 1512/1000MHz  1.08  12%   0%  12%   0%   0%   0%  56.0°C
09:28:21: 1512/1000MHz  1.06  12%   0%  12%   0%   0%   0%  56.0°C
09:28:36: 1512/1000MHz  1.05  12%   0%  12%   0%   0%   0%  56.0°C
09:28:51: 1512/1000MHz  1.09  12%   0%  12%   0%   0%   0%  56.0°C
09:29:07: 1512/1000MHz  1.07  12%   0%  12%   0%   0%   0%  56.0°C
09:29:22: 1512/1000MHz  1.06  12%   0%  12%   0%   0%   0%  55.0°C
09:29:37: 1512/1000MHz  1.04  12%   0%  12%   0%   0%   0%  56.0°C
09:29:52: 1512/1000MHz  1.03  12%   0%  12%   0%   0%   0%  56.0°C
09:30:07: 1512/1000MHz  1.02  12%   0%  12%   0%   0%   0%  56.0°C

System health while running 7-zip multi core benchmark:

Time       big.LITTLE   load %cpu %sys %usr %nice %io %irq   Temp
09:30:14: 1512/1000MHz  1.18  10%   0%   7%   0%   3%   0%  55.0°C
09:30:26: 1512/1000MHz  2.39  85%   1%  84%   0%   0%   0%  61.0°C
09:30:39: 1512/1000MHz  3.63  97%   0%  97%   0%   0%   0%  64.0°C
09:30:51: 1512/1000MHz  3.93  74%   1%  73%   0%   0%   0%  63.0°C
09:31:05: 1512/1000MHz  4.36  97%   0%  96%   0%   0%   0%  64.0°C
09:31:16: 1512/1000MHz  4.54  69%   1%  68%   0%   0%   0%  63.0°C
09:31:33: 1512/1000MHz  5.51  95%   2%  93%   0%   0%   0%  65.0°C
09:31:45: 1512/1000MHz  5.81  72%   0%  72%   0%   0%   0%  59.0°C
09:31:56: 1512/1000MHz  5.91  89%   2%  86%   0%   0%   0%  65.0°C
09:32:08: 1512/1000MHz  6.53  98%   2%  95%   0%   0%   0%  65.0°C
09:32:22: 1512/1000MHz  6.83  95%  44%  50%   0%   0%   0%  65.0°C
09:32:37: 1512/1000MHz  7.01  92%   3%  88%   0%   0%   0%  67.0°C
09:32:48: 1512/1000MHz  7.37  74%   1%  73%   0%   0%   0%  65.0°C
09:33:04: 1512/1000MHz  7.55  94%   0%  94%   0%   0%   0%  67.0°C
09:33:17: 1512/1000MHz  7.32  80%   1%  79%   0%   0%   0%  66.0°C
09:33:31: 1512/1000MHz  7.43  97%   0%  96%   0%   0%   0%  67.0°C
09:33:43: 1512/1000MHz  6.77  70%   1%  68%   0%   0%   0%  66.0°C
09:33:59: 1512/1000MHz  6.87  93%   2%  91%   0%   0%   0%  67.0°C
09:34:11: 1512/1000MHz  6.95  74%   0%  73%   0%   0%   0%  62.0°C
09:34:23: 1512/1000MHz  6.64  87%   2%  84%   0%   0%   0%  67.0°C
09:34:34: 1512/1000MHz  6.86  97%   2%  94%   0%   0%   0%  67.0°C
09:35:08: 1512/1000MHz  7.56  90%  53%  35%   0%   1%   0%  67.0°C
09:35:21: 1512/1000MHz  7.57  83%   1%  82%   0%   0%   0%  67.0°C
09:35:37: 1512/1000MHz  7.52  89%   1%  88%   0%   0%   0%  69.0°C
09:35:49: 1512/1000MHz  7.38  82%   0%  82%   0%   0%   0%  67.0°C
09:36:06: 1512/1000MHz  7.47  94%   1%  92%   0%   0%   0%  69.0°C
09:36:18: 1512/1000MHz  7.30  77%   0%  76%   0%   0%   0%  68.0°C
09:36:29: 1512/1000MHz  7.56  96%   2%  93%   0%   0%   0%  69.0°C
09:36:43: 1512/1000MHz  7.63  94%   0%  94%   0%   0%   0%  70.0°C
09:36:54: 1512/1000MHz  7.02  58%   1%  57%   0%   0%   0%  68.0°C
09:37:06: 1512/1000MHz  7.25  94%   2%  92%   0%   0%   0%  69.0°C
09:37:30: 1512/1000MHz  7.80  96%  36%  59%   0%   0%   0%  69.0°C
09:37:44: 1512/1000MHz  7.33  90%   4%  85%   0%   0%   0%  71.0°C

##########################################################################

Linux 5.15.46-flippy-73+o (armbian) 	06/15/22 	_aarch64_	(8 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          16.28    0.01    1.43    2.70    0.00   79.59

Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
mmcblk1           3.87       128.10       105.66       283.94     461094     380314    1022068
mmcblk2           0.05         1.16         0.00         0.00       4180          0          0
zram0           618.20      1120.16      1352.64         0.00    4032100    4868892          0
zram1             0.41         0.50         7.63         0.00       1808      27456          0
zram2             0.34         0.62         0.80         0.00       2228       2884          0

               total        used        free      shared  buff/cache   available
Mem:           1.8Gi       145Mi       1.6Gi       0.0Ki        24Mi       1.6Gi
Swap:          904Mi        52Mi       852Mi

Filename				Type		Size	Used	Priority
/dev/zram0                             	partition	926468	53284	5

CPU sysfs topology (clusters, cpufreq members, clockspeeds)
                 cpufreq   min    max
 CPU    cluster  policy   speed  speed   core type
  0        0        0      100    1512   Cortex-A53 / r0p4
  1        0        0      100    1512   Cortex-A53 / r0p4
  2        0        0      100    1512   Cortex-A53 / r0p4
  3        0        0      100    1512   Cortex-A53 / r0p4
  4        1        4      100    1000   Cortex-A53 / r0p4
  5        1        4      100    1000   Cortex-A53 / r0p4
  6        1        4      100    1000   Cortex-A53 / r0p4
  7        1        4      100    1000   Cortex-A53 / r0p4

Architecture:                    aarch64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
CPU(s):                          8
On-line CPU(s) list:             0-7
Thread(s) per core:              1
Core(s) per socket:              4
Socket(s):                       2
Vendor ID:                       ARM
Model:                           4
Model name:                      Cortex-A53
Stepping:                        r0p4
CPU max MHz:                     1512.0000
CPU min MHz:                     100.0000
BogoMIPS:                        48.00
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Not affected
Vulnerability Spectre v1:        Mitigation; __user pointer sanitization
Vulnerability Spectre v2:        Not affected
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fp asimd evtstrm aes pmull sha1 sha2 crc32 cpuid

SoC guess: Amlogic Meson GXM (S912) Revision 22:a (82:2)
DT compat: libretech,aml-s912-pc
           amlogic,s912
           amlogic,meson-gxm
 Compiler: /usr/bin/gcc (Debian 10.2.1-6) 10.2.1 20210110 / aarch64-linux-gnu
 Userland: arm64
   Kernel: 5.15.46-flippy-73+o/aarch64
           CONFIG_HZ=300
           CONFIG_HZ_300=y
           CONFIG_HZ_PERIODIC=y
           CONFIG_PREEMPTION=y
           CONFIG_PREEMPT=y
           CONFIG_PREEMPT_COUNT=y
           CONFIG_PREEMPT_NOTIFIERS=y
           CONFIG_PREEMPT_RCU=y
           raid6: neonx8   gen()  2225 MB/s
           raid6: neonx8   xor()  1605 MB/s
           raid6: neonx4   gen()  2221 MB/s
           raid6: neonx4   xor()  1540 MB/s
           raid6: neonx2   gen()  2042 MB/s
           raid6: neonx2   xor()  1433 MB/s
           raid6: neonx1   gen()  1662 MB/s
           raid6: neonx1   xor()  1178 MB/s
           raid6: int64x8  gen()  1560 MB/s
           raid6: int64x8  xor()   814 MB/s
           raid6: int64x4  gen()  1673 MB/s
           raid6: int64x4  xor()   839 MB/s
           raid6: int64x2  gen()  1480 MB/s
           raid6: int64x2  xor()   767 MB/s
           raid6: int64x1  gen()  1123 MB/s
           raid6: int64x1  xor()   583 MB/s
           raid6: using algorithm neonx8 gen() 2225 MB/s
           raid6: .... xor() 1605 MB/s, rmw enabled
           raid6: using neon recovery algorithm
           xor: measuring software checksum speed
           xor: using function: 32regs (2908 MB/sec)

| Libre Computer AML-S912-PC | 1512/1000 MHz | 5.15 | Armbian 22.08.0-trunk Bullseye arm64 | 5980 | 91890 | 659290 | 1650 | 5170 | - |